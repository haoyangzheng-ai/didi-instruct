# Discrete Diffusion Divergence Instruct (DiDi-Instruct)
name: didi_instruct

# ---- Model Architecture (must match the teacher model) ----
backbone: dit
parameterization: subs
time_conditioning: False
subs_masking: False
causal_attention: False
ignore_bos: False
T: 0 # Continuous time

# ---- Core Distillation Parameters ----
student_num_steps: 2              # N: The number of inference steps for the student model.
num_samples_per_prompt: 4         # G: Number of samples per prompt for GRPO reward normalization.
tau_mode: 'beta11'                # Sampling distribution for the intermediate timestep tau.
remask_prob: 0.0

# ---- Discriminator Parameters ----
discriminator_lr: 1e-5                # Learning rate for the discriminator.
discriminator_unfreeze_blocks: 4      # Number of final transformer blocks to unfreeze and train in the discriminator.
discriminator_warmup_steps: 0         # Steps to train only the discriminator before starting student updates.
label_smoothing: 0.1                  # Label smoothing for discriminator loss to prevent overconfidence.
discriminator_optim:
  weight_decay: 0
  beta1: 0.9
  beta2: 0.999
  eps: 1e-8

# ---- Student Regularization & Stability ----

# ---- Reward Shaping & Advantage Calculation ----

# ---- Student Generation & EMA ----

# ---- Generation Parameters ----

# --- Guided Sampling Hyperparameters ---
num_candidates: 4
guidance_scale_start: 30.0
guidance_scale_end: 40.0
rerank_steps_ratio: 0.5

# ---- Logging & Saving ----
output_dir: "/your_output_dir/"
print_every: 10
save_after_n_steps: 200
lr_scheduler:
  name: cosine
  warmup_steps: 1000
  warmup_ratio: 0.1
  min_lr: 1e-6
